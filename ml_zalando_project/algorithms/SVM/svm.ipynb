{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Nbg39G9BaXSk"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import lru_cache, reduce\n",
        "from scipy import ndimage\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "gkHkl8ZXcn93",
        "outputId": "4a3ac17c-02fe-4c3f-d3f7-83067f85f2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# this code ran in colab and used files from my google-drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K3kWHFdejHdv"
      },
      "outputs": [],
      "source": [
        "# load files into arrays\n",
        "fashion_train_array = np.load('/content/drive/My Drive/zalando_all/fashion_train.npy') # 10000,785\n",
        "all_input = np.load('/content/drive/My Drive/zalando_all/fashion_train.npy') # 10000,785\n",
        "fashion_test_array = np.load('/content/drive/My Drive/zalando_all/fashion_test.npy') # 5000, 785\n",
        "dilated_train_array = np.load('/content/drive/My Drive/zalando_all/dilated_input.npy') # 10000, 784\n",
        "lda3_projector = np.load('/content/drive/My Drive/zalando_all/sorted_eigvecs_3.npy')\n",
        "lda4_projector = np.load('/content/drive/My Drive/zalando_all/sorted_eigvecs_4.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kHxGVv5Acw9f"
      },
      "outputs": [],
      "source": [
        "# take labels and features from train and test\n",
        "fashion_train_features = fashion_train_array[:, :-1]\n",
        "fashion_train_labels = fashion_train_array[:, -1]\n",
        "fashion_test_features = fashion_test_array[:, :-1]\n",
        "fashion_test_labels = fashion_test_array[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LQw2WnTXjtz2"
      },
      "outputs": [],
      "source": [
        "# shuffle and normalization\n",
        "np.random.shuffle(all_input)\n",
        "fashion_train_features = fashion_train_features / np.max(fashion_train_features)\n",
        "fashion_test_features = fashion_test_features / np.max(fashion_train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bDyVk2Avj-Hn"
      },
      "outputs": [],
      "source": [
        "# label extraction\n",
        "labels = all_input[:, -1]\n",
        "current_train = all_input[:, :-1]\n",
        "\n",
        "# projecting normalized train and test set with lda\n",
        "d3_projected = np.dot(current_train, lda3_projector)\n",
        "d4_projected = np.dot(current_train, lda4_projector)\n",
        "\n",
        "# smae for test set\n",
        "d3_projected_test = np.dot(fashion_test_features, lda3_projector)\n",
        "d4_projected_test = np.dot(fashion_test_features, lda4_projector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KFLdQXjfkRaq"
      },
      "outputs": [],
      "source": [
        "# create different label inputs for classifier\n",
        "labels_0, labels_1, labels_2, labels_3, labels_4 = labels.astype(np.int8), labels.astype(np.int8), labels.astype(np.int8), labels.astype(np.int8), labels.astype(np.int8)\n",
        "labels_all = [labels_0, labels_1, labels_2, labels_3, labels_4]\n",
        "for idx,l in enumerate(labels_all):\n",
        "  l[labels == idx] = 1\n",
        "  l[labels != idx] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "eqYfbVGKluAq",
        "outputId": "ae855dfb-3347-490c-c126-0ff334637019"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([-1,  1], dtype=int8), array([7995, 2005]))"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# just for check\n",
        "np.unique(labels_3, return_counts = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DCaJaPtTl6oJ"
      },
      "outputs": [],
      "source": [
        "# cross_validation datasets\n",
        "d3_train_x_1 = d3_projected[:8000, :]\n",
        "d3_train_x_2 = d3_projected[2000:, :]\n",
        "d3_train_x_3 = np.concatenate((d3_projected[:2000, :], d3_projected[4000:, :]), axis = 0)\n",
        "d3_train_x_4 = np.concatenate((d3_projected[:4000, :], d3_projected[6000:, :]), axis = 0)\n",
        "d3_train_x_5 = np.concatenate((d3_projected[:6000, :], d3_projected[8000:, :]), axis = 0)\n",
        "\n",
        "d3_test_x_1 = d3_projected[8000:]\n",
        "d3_test_x_2 = d3_projected[:2000]\n",
        "d3_test_x_3 = d3_projected[2000:4000]\n",
        "d3_test_x_4 = d3_projected[4000:6000]\n",
        "d3_test_x_5 = d3_projected[6000:8000]\n",
        "\n",
        "d4_train_x_1 = d4_projected[:8000, :]\n",
        "d4_train_x_2 = d4_projected[2000:, :]\n",
        "d4_train_x_3 = np.concatenate((d4_projected[:2000, :], d4_projected[4000:, :]), axis = 0)\n",
        "d4_train_x_4 = np.concatenate((d4_projected[:4000, :], d4_projected[6000:, :]), axis = 0)\n",
        "d4_train_x_5 = np.concatenate((d4_projected[:6000, :], d4_projected[8000:, :]), axis = 0)\n",
        "\n",
        "d4_test_x_1 = d4_projected[8000:]\n",
        "d4_test_x_2 = d4_projected[:2000]\n",
        "d4_test_x_3 = d4_projected[2000:4000]\n",
        "d4_test_x_4 = d4_projected[4000:6000]\n",
        "d4_test_x_5 = d4_projected[6000:8000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8p0Zx0aMpwbA"
      },
      "outputs": [],
      "source": [
        "# method built mostly from hw7 notebook\n",
        "def run_classifer(train_x, train_y, test_x, test_y, batch_size, train_steps): # session started\n",
        "  # start session\n",
        "  sess = tf.Session()\n",
        "  # give according lda-d data you want to feed\n",
        "  dim = train_x.shape[1]\n",
        "\n",
        "  # init placeholders\n",
        "  x = tf.placeholder(shape = [None, dim], dtype = tf.float32)\n",
        "  r = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
        "  prediction_grid = tf.placeholder(shape = [None, dim], dtype = tf.float32)\n",
        "  prediction_r = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
        "\n",
        "  # create variable fro svm\n",
        "  alpha = tf.Variable(tf.random_normal(shape = [1, batch_size]))\n",
        "\n",
        "  #declare kernel gaussian kernel\n",
        "  gamma = tf.constant(2.0)\n",
        "  dist = tf.reduce_sum(tf.square(x), 1)\n",
        "  sq_dist = tf.subtract(tf.add(dist, dist), tf.multiply(2.0, tf.matmul(x, tf.transpose(x))))\n",
        "  kernel = tf.exp(tf.multiply(-gamma, tf.abs(sq_dist)))\n",
        "\n",
        "  # declare linear kernel\n",
        "  #kernel = tf.matmul(x, tf.transpose(x))\n",
        "  #kernel = tf.tensordot(x, tf.transpose(x), 1)\n",
        "\n",
        "  # prediction kernel gaussian\n",
        "  tr = tf.reshape(tf.reduce_sum(tf.square(x), 1), [-1,1])\n",
        "  te = tf.reduce_sum(tf.square(prediction_grid), 1)\n",
        "  pred_sq_dist = tf.add(tf.subtract(tr, tf.multiply(2.0, tf.matmul(x, tf.transpose(prediction_grid)))), te)\n",
        "  pred_kernel = tf.exp(tf.multiply(-gamma, tf.abs(pred_sq_dist)))\n",
        "\n",
        "  # linear prediction kernel\n",
        "  #pred_kernel = tf.matmul(x, tf.transpose(prediction_grid))\n",
        "  #pred_kernel = tf.tensordot(x, tf.transpose(prediction_grid), 1)\n",
        "\n",
        "  # compute loss function\n",
        "  alpha_sum = tf.reduce_sum(alpha)\n",
        "\n",
        "  r_matrix = tf.matmul(r, tf.transpose(r))\n",
        "  alpha_prod = tf.matmul(tf.transpose(alpha), alpha)\n",
        "  double_sum = tf.reduce_sum(tf.multiply(kernel, tf.multiply(alpha_prod, r_matrix)))\n",
        "\n",
        "  loss = tf.negative(tf.subtract(alpha_sum, double_sum))\n",
        "\n",
        "  # predict\n",
        "  pred_output = tf.matmul(tf.multiply(tf.transpose(r), alpha), pred_kernel)\n",
        "  norm_pred_output = pred_output - tf.reduce_mean(pred_output)  \n",
        "  #pred = tf.sign(pred_output - tf.reduce_mean(pred_output))\n",
        "  pred = tf.sign(pred_output)\n",
        "  accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(pred), tf.squeeze(prediction_r)), tf.float32))\n",
        "\n",
        "  # declare optimizer\n",
        "  my_opt = tf.train.GradientDescentOptimizer(0.0005)\n",
        "  train_step = my_opt.minimize(loss)\n",
        "\n",
        "  init = tf.global_variables_initializer()\n",
        "  sess.run(init)\n",
        "\n",
        "  # training\n",
        "  temp_losses = []\n",
        "  batch_accs = []\n",
        "  np.random.seed(265)\n",
        "  alphas = []\n",
        "  r_s = []\n",
        "  pred_outputs = []\n",
        "  for i in range(train_steps):\n",
        "    batch_idxs = np.random.choice(8000, size = batch_size)\n",
        "    batch_x = train_x[batch_idxs]\n",
        "    batch_r = np.transpose([train_y[batch_idxs]])\n",
        "    sess.run(train_step, feed_dict= {x:batch_x, r:batch_r})\n",
        "\n",
        "    temp_loss = sess.run(loss, feed_dict={x:batch_x, r:batch_r})\n",
        "    temp_losses.append(temp_loss)\n",
        "\n",
        "    current_pred_out = sess.run(pred_output, feed_dict = {x: batch_x, r: batch_r, prediction_grid: test_x, prediction_r : np.transpose([test_y])})\n",
        "    pred_outputs.append(current_pred_out)\n",
        "\n",
        "    current_alpha = sess.run(alpha, feed_dict = {x: batch_x, r: batch_r, prediction_grid: test_x, prediction_r : np.transpose([test_y])})\n",
        "    alphas.append(current_alpha)\n",
        "\n",
        "    current_r = sess.run(r, feed_dict = {x: batch_x, r: batch_r, prediction_grid: test_x, prediction_r : np.transpose([test_y])})\n",
        "    r_s.append(current_r)\n",
        "\n",
        "    batch_acc = sess.run(accuracy, feed_dict = {x: batch_x, r: batch_r, prediction_grid: test_x, prediction_r : np.transpose([test_y])})\n",
        "    batch_accs.append(batch_acc)\n",
        "\n",
        "    if (i+1)%(int(train_steps/6)) == 0:\n",
        "      print(\"Step #{}\".format(i+1))\n",
        "      print(\"Loss = \", temp_loss)\n",
        "      #print(f\"x: {sess.run(x, feed_dict={x:batch_x, r:batch_r}).shape}\")\n",
        "      #print(f\"r: {sess.run(r, feed_dict={x:batch_x, r:batch_r}).shape}\")\n",
        "      #print(f\"alpha: {sess.run(alpha, feed_dict={x:batch_x, r:batch_r})}\")\n",
        "      print(sess.run(accuracy, feed_dict = {x: batch_x, r: batch_r, prediction_grid: test_x, prediction_r : np.transpose([test_y])}))\n",
        "      print(sess.run(pred_kernel, feed_dict = {x: batch_x, r: batch_r, prediction_grid: test_x, prediction_r : np.transpose([test_y])}).shape)\n",
        "    \n",
        "  sess.close()\n",
        "  return batch_accs[-1], pred_outputs[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "xnGQiX9Z9YH5",
        "outputId": "9634d692-298a-450a-ca3e-2c53ad83f87d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step #500\n",
            "Loss =  139.30219\n",
            "0.6325\n",
            "(500, 2000)\n",
            "Step #1000\n",
            "Loss =  9.597321\n",
            "0.7675\n",
            "(500, 2000)\n",
            "Step #1500\n",
            "Loss =  -27.07608\n",
            "0.8815\n",
            "(500, 2000)\n",
            "Step #2000\n",
            "Loss =  -39.673294\n",
            "0.92\n",
            "(500, 2000)\n",
            "Step #2500\n",
            "Loss =  -55.318123\n",
            "0.9285\n",
            "(500, 2000)\n",
            "Step #3000\n",
            "Loss =  -49.283123\n",
            "0.924\n",
            "(500, 2000)\n",
            "Step #500\n",
            "Loss =  144.4025\n",
            "0.667\n",
            "(500, 2000)\n",
            "Step #1000\n",
            "Loss =  28.830574\n",
            "0.7645\n",
            "(500, 2000)\n",
            "Step #1500\n",
            "Loss =  -18.231041\n",
            "0.872\n",
            "(500, 2000)\n",
            "Step #2000\n",
            "Loss =  -28.252453\n",
            "0.961\n",
            "(500, 2000)\n",
            "Step #2500\n",
            "Loss =  -38.512108\n",
            "0.988\n",
            "(500, 2000)\n",
            "Step #3000\n",
            "Loss =  -40.60344\n",
            "0.9875\n",
            "(500, 2000)\n",
            "Step #500\n",
            "Loss =  138.4274\n",
            "0.613\n",
            "(500, 2000)\n",
            "Step #1000\n",
            "Loss =  22.154938\n",
            "0.763\n",
            "(500, 2000)\n",
            "Step #1500\n",
            "Loss =  -18.654037\n",
            "0.8775\n",
            "(500, 2000)\n",
            "Step #2000\n",
            "Loss =  -37.196045\n",
            "0.9365\n",
            "(500, 2000)\n",
            "Step #2500\n",
            "Loss =  -45.73643\n",
            "0.949\n",
            "(500, 2000)\n",
            "Step #3000\n",
            "Loss =  -44.41781\n",
            "0.9465\n",
            "(500, 2000)\n",
            "Step #500\n",
            "Loss =  139.88055\n",
            "0.639\n",
            "(500, 2000)\n",
            "Step #1000\n",
            "Loss =  14.980392\n",
            "0.801\n",
            "(500, 2000)\n",
            "Step #1500\n",
            "Loss =  -27.887558\n",
            "0.871\n",
            "(500, 2000)\n",
            "Step #2000\n",
            "Loss =  -36.624443\n",
            "0.9325\n",
            "(500, 2000)\n",
            "Step #2500\n",
            "Loss =  -44.199913\n",
            "0.9485\n",
            "(500, 2000)\n",
            "Step #3000\n",
            "Loss =  -48.4208\n",
            "0.949\n",
            "(500, 2000)\n",
            "Step #500\n",
            "Loss =  140.11798\n",
            "0.5865\n",
            "(500, 2000)\n",
            "Step #1000\n",
            "Loss =  7.6207657\n",
            "0.737\n",
            "(500, 2000)\n",
            "Step #1500\n",
            "Loss =  -22.544167\n",
            "0.826\n",
            "(500, 2000)\n",
            "Step #2000\n",
            "Loss =  -51.701157\n",
            "0.8715\n",
            "(500, 2000)\n",
            "Step #2500\n",
            "Loss =  -49.27163\n",
            "0.8985\n",
            "(500, 2000)\n",
            "Step #3000\n",
            "Loss =  -45.324806\n",
            "0.9035\n",
            "(500, 2000)\n"
          ]
        }
      ],
      "source": [
        "# running the training\n",
        "pred_outs = []\n",
        "accs = []\n",
        "for current_labels in labels_all:\n",
        "  current_accs, current_pred_outs = run_classifer(train_x = d4_train_x_1, train_y = current_labels[:8000], test_x = d4_test_x_1, test_y = current_labels[8000:], batch_size = 500, train_steps = 3000)\n",
        "  pred_outs.append(current_pred_outs)\n",
        "  accs.append(current_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J3UbXCtoT9lJ"
      },
      "outputs": [],
      "source": [
        "# calculating accuracy\n",
        "accuracy = 0\n",
        "confusion_matrix = np.zeros((5,5))\n",
        "max_arrays = np.zeros((2000,5), dtype = np.float64)\n",
        "predictions = np.zeros(2000, dtype = np.int8)\n",
        "for idx, label in enumerate(labels[8000:]):\n",
        "  max_array = np.array([pred_outs[0][0][idx], pred_outs[1][0][idx], pred_outs[2][0][idx], pred_outs[3][0][idx], pred_outs[4][0][idx]])\n",
        "  max_arrays[idx, :] = max_array\n",
        "  predictions[idx] = np.argmax(max_array)\n",
        "  if label == np.argmax(max_array):\n",
        "    accuracy += 1\n",
        "  confusion_matrix[label, np.argmax(max_array)] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "QSlQTeLceSsh",
        "outputId": "38581d43-5d66-4894-f96e-dbdeef6e2cc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[337.,   0.,  10.,  17.,  31.],\n",
              "       [  0., 385.,   1.,   8.,   2.],\n",
              "       [  9.,   3., 353.,   7.,  27.],\n",
              "       [ 25.,   9.,   7., 346.,  16.],\n",
              "       [ 64.,   0.,  44.,  15., 284.]])"
            ]
          },
          "execution_count": 166,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "7fLFTI4rg0U5",
        "outputId": "8a9268b1-0a09-4bb7-fbb6-a4581afbcfe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8525"
            ]
          },
          "execution_count": 167,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# not acc\n",
        "accuracy / 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "TZJre9_ISgEL",
        "outputId": "18c88f4d-995d-4c7f-e619-418a644917ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "execution_count": 168,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WoPuDQzohNxG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "my_df = pd.DataFrame({'true': list(labels[8000:]), 'predicted': predictions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UfQNTaKfurjY"
      },
      "outputs": [],
      "source": [
        "# save labels\n",
        "from google.colab import files\n",
        "my_df.to_csv('d4_cv_1.csv', header = True, index = False, sep = ',')\n",
        "files.download('d4_cv_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5msmd-1tvBb4"
      },
      "outputs": [],
      "source": [
        "max_df = pd.DataFrame(max_arrays, columns = list('01234'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "colab_type": "code",
        "id": "I65sFnklzFUe",
        "outputId": "d13d0cb5-7243-431c-e7ea-4b6b4715cd5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.002150</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>-0.001684</td>\n",
              "      <td>-0.001253</td>\n",
              "      <td>-0.001750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.208151</td>\n",
              "      <td>-0.100838</td>\n",
              "      <td>-0.181143</td>\n",
              "      <td>-0.116698</td>\n",
              "      <td>-0.212389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.205672</td>\n",
              "      <td>-0.174433</td>\n",
              "      <td>-0.219351</td>\n",
              "      <td>0.183180</td>\n",
              "      <td>-0.223888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000898</td>\n",
              "      <td>-0.004479</td>\n",
              "      <td>-0.005336</td>\n",
              "      <td>-0.003891</td>\n",
              "      <td>-0.002175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.269537</td>\n",
              "      <td>-0.199138</td>\n",
              "      <td>-0.257518</td>\n",
              "      <td>0.290814</td>\n",
              "      <td>-0.340472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>-0.020336</td>\n",
              "      <td>-0.011938</td>\n",
              "      <td>-0.019064</td>\n",
              "      <td>0.017257</td>\n",
              "      <td>-0.017996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>-1.100574</td>\n",
              "      <td>0.914975</td>\n",
              "      <td>-1.065973</td>\n",
              "      <td>-1.073578</td>\n",
              "      <td>-1.257206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>-0.000246</td>\n",
              "      <td>-0.000117</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>-0.000267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>-0.010151</td>\n",
              "      <td>-0.174000</td>\n",
              "      <td>-0.202427</td>\n",
              "      <td>-0.178860</td>\n",
              "      <td>-0.005832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>-0.086712</td>\n",
              "      <td>-0.065755</td>\n",
              "      <td>-0.044678</td>\n",
              "      <td>-0.047344</td>\n",
              "      <td>0.069010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2         3         4\n",
              "0    -0.002150  0.000823 -0.001684 -0.001253 -0.001750\n",
              "1     0.208151 -0.100838 -0.181143 -0.116698 -0.212389\n",
              "2    -0.205672 -0.174433 -0.219351  0.183180 -0.223888\n",
              "3     0.000898 -0.004479 -0.005336 -0.003891 -0.002175\n",
              "4    -0.269537 -0.199138 -0.257518  0.290814 -0.340472\n",
              "...        ...       ...       ...       ...       ...\n",
              "4995 -0.020336 -0.011938 -0.019064  0.017257 -0.017996\n",
              "4996 -1.100574  0.914975 -1.065973 -1.073578 -1.257206\n",
              "4997 -0.000246 -0.000117  0.000258 -0.000250 -0.000267\n",
              "4998 -0.010151 -0.174000 -0.202427 -0.178860 -0.005832\n",
              "4999 -0.086712 -0.065755 -0.044678 -0.047344  0.069010\n",
              "\n",
              "[5000 rows x 5 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# all projections\n",
        "max_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PjN_wiMNzJTC"
      },
      "outputs": [],
      "source": [
        "max_df.to_csv('ld4_max.csv', header = True, index = False, sep = ',')\n",
        "files.download('ld4_max.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "M4uEcO9qzizA"
      },
      "outputs": [],
      "source": []
    }
  ]
}